\chapter{Теоретическая часть}
\label{cha:theory}

\section{Определения}

\textbf{Корпус текстов} --- множество подобранных и определённым образом обработанных текстов.

\textbf{Токен} --- элементарная единица разбиения корпуса.

\textbf{Токенизация} --- процесс разбиения корпуса на токены с присвоением им уникальных числовых идентификаторов.

\textbf{Языковая модель} --- распределение $P(w_t | w_1,w_2,w_3,\dots,w_n)$ вероятностей встретить токен $w_t$ в корпусе сразу после $n$ токенов $w_i$, $i\in[1, n]$, идущих подряд, где $w_i \in W \, \forall i$, $W$ --- множество всех токенов корпуса, $n$ --- длина контекста модели.

\textbf{Длина контекста} --- количество $n$ токенов $w_i$, $i\in[0, n]$, предшествующих токену $w_t$, от которых зависит вероятность появления в тексте токена $w_t$.

\textbf{Дообучение} --- процесс обучения уже обученной на некоторых данных модели машинного обучения на новых данных. В случае языковой модели это означает подстройку модели под новое распределение токенов.

\textbf{Перплексия} --- мера схожести двух вероятностных распределений, используемая для оценки качества генерации текста языковой моделью. Перплексия задаётся формулой \ref*{eq:perplexity}.
\begin{equation}
    \label{eq:perplexity}
    \textrm{PP}(W)=\sqrt[n]{\frac{1}{P(w_1,w_2,\dots,w_n)}}
\end{equation}

\section{Постановка задачи}

Дано:
\begin{enumerate}
    \item корпус, состоящий из текстов, принадлежащих конкретной предметной области,
    \item предобученная нейросетевая языковая модель, хорошо моделирующая вероятностное распределение слов в естественном языке.
\end{enumerate}
Требуется:
\begin{enumerate}
    \item дообучить данную языковую модель на данных из корпуса, получив новую языковую модель, моделирующую распределение вероятностей слов в данном корпусе,
    \item реализовать возможность применения её для генерации новых текстов, принадлежащих предметной области данного корпуса,
    \item создать графический интерфейс для взаимодействия пользователя с моделью,
    \item подготовить получившееся приложение для дистрибуции.
\end{enumerate}

\section{Нейронные сети}

\subsection{Однослойный перцептрон}

Одной из простейших моделей машинного обучения является однослойный перцептрон. Он позволяет, обучаясь на выборке данных, решать задачу линейной регрессии, то есть, устанавливать зависимость между зависимой переменной $y$ и независимыми переменными $x$ при условии, что между ними существует линейная зависимость, которую можно описать уравнением \ref*{eq:lin_reg}. В нём всегда $x_0\equiv 1$, а $w_0$ называется смещением, так как изменение этой компоненты приводит к увеличению или уменьшению $y$ на постоянное значение.
\begin{equation}
    \label{eq:lin_reg}
    y=\mathbf{w}\cdot\mathbf{x}=w_0x_0+w_1x_1+w_2x_2+\dots+w_nx_n,\quad x_0\equiv 1
\end{equation}

В этом уравнении неизвестными являются компоненты вектора $\mathbf{w}$, найдя которые, можно получить взаимосвязь между $x$ и $y$. Обучающая выборка данных представляет собой матрицу $\mathbf{X}$ размера $m \times (n+1)$ наблюдений вектора $\mathbf{x}$ и вектор $\mathbf{y}$ размера $m$, где $y_i=\mathbf{w} \cdot \mathbf{x}_i$, $\mathbf{x}_i$ --- $i$-я строка матрицы $\mathbf{X}$, как показано в уравнении \ref*{eq:lin_reg_dataset}.
\begin{equation}
    \label{eq:lin_reg_dataset}
    \mathbf{X}\mathbf{w}=
    \left(\begin{matrix}
        x_0^1 & x_1^1 & x_2^1 & x_3^1 & \dots & x_n^1 \\
        x_0^2 & x_1^2 & x_2^2 & x_3^2 & \dots & x_n^2 \\
        x_0^3 & x_1^3 & x_2^3 & x_3^3 & \dots & x_n^3 \\
        x_0^4 & x_1^4 & x_2^4 & x_3^4 & \dots & x_n^4 \\
        \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
        x_0^m & x_1^m & x_2^m & x_3^m & \dots & x_n^m
    \end{matrix}\right)
    \left(\begin{matrix}
        w_0 \\
        w_1 \\
        w_2 \\
        \vdots \\
        w_n
    \end{matrix}\right)=
    \left(\begin{matrix}
        y_1 \\
        y_2 \\
        y_3 \\
        y_4 \\
        \vdots \\
        y_m
    \end{matrix}\right)=\mathbf{y}
\end{equation}

Уравнения \ref*{eq:lin_reg_dataset} имеет одно решение относительно $\mathbf{w}$ тогда и только тогда, когда $\rank \mathbf{X} = n$. Если $\rank \mathbf{X} < n$, уравнение имеет бесконечное число решений, и если $\rank \mathbf{X} > n$, уравнение не имеет решений. Но на практике данных обычно больше, чем компонент в векторе $\mathbf{w}$, поэтому используется аппроксимация методом наименьших квадратов, суть которой состоит в том, чтобы путём решения задачи минимизации, показанной в уравнении \ref*{eq:lsm}, найти такую прямую, чтобы функция потерь $L(\mathbf{y},\hat{\mathbf{y}})$ была минимальна.
\begin{equation}
    \label{eq:lsm}
    \begin{cases}
        \mathbf{w} = \arg\min\limits_\mathbf{w} L(\mathbf{y},\hat{\mathbf{y}}), \\
        \hat{\mathbf{y}}=\mathbf{X}\mathbf{w}
    \end{cases}
\end{equation}

Из курса математической статистики известно, что лучше всего в данной задаче подходит функция потерь $\MSE$ или средний квадрат ошибки (уравнение \ref*{eq:mse}). При использовании этой функции потерь дисперсия ошибки получается наименьшей.
\begin{equation}
    \label{eq:mse}
    \MSE(\mathbf{y},\hat{\mathbf{y}})=\sum\limits_{i=1}^m(\mathbf{x}_i^\mathsf{T}\mathbf{w}-y_i)^2=(\mathbf{X}\mathbf{w}-\mathbf{y})^\mathsf{T}(\mathbf{X}\mathbf{w}-\mathbf{y})
\end{equation}

Минимум функции потерь можно найти градиентными методами, например, методом Adam, так как она дифференцируема, и её производную можно вычислить аналитически (уравнение \ref*{eq:mse_der}). Процесс поиска минимума функции потерь модели называют обучением.
\begin{equation}
    \label{eq:mse_der}
    \frac{\partial\MSE}{\partial \mathbf{w}}(\mathbf{w})=2\mathbf{X}^\mathsf{T}(\mathbf{X}\mathbf{w}-\mathbf{y})
\end{equation}

Если же от модели требуется предсказывать не численные характеристики объектов, а относить их к той или иной группе, то такая задача называется задачей классификации, а модель --- логистической регрессией.

В этом случае требуется не аппроксимировать точки гиперплоскостью, а сделать так, чтобы гиперплоскость отделяла точки одного класса от точек другого (рисунок \ref*{fig:log_reg}). Для этого к выходу линейной регрессии дополнительно применяют функцию с областью значений $[0, 1]$, чтобы выход модели можно было интерпретировать как вероятность принадлежности объекта заданному классу \cite{art:linear_models}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{../inc/images/logistic_regression.png}
    \caption{Работа логистической регрессии в случае бинарной классификации}
    \label{fig:log_reg}
\end{figure}

\begin{equation}
    \label{eq:sigmoid}
    \sigma(x)=\frac{1}{1+e^{-x}}
\end{equation}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[domain=-6:6]
        \draw[thin,color=gray] (-6.2,-1.2) grid (6.2,2.2);
      
        \draw[line width=0.35mm,->] (-6.2,0) -- (6.2,0) node[right] {$x$};
        \draw[line width=0.35mm,->] (0,-1.2) -- (0,2.2) node[above] {$y$};

        \draw[line width=0.4mm,color=blue,smooth] plot (\x,{1/(1+exp(-\x))});

        \draw[] (0.05, 1) node[right] {$1$};
        \draw[] (1, -0.05) node[below] {$1$};
    \end{tikzpicture}
    \caption{График сигмоиды}
    \label{fig:sigmoid}
\end{figure}

\begin{equation}
    \label{eq:softmax}
    \Softmax(\mathbf{x})=\frac{1}{\sum\limits_{i=1}^n e^{x_i}}
    \left(\begin{matrix}
        e^{x_1} \\
        e^{x_2} \\
        e^{x_3} \\
        \vdots \\
        e^{x_n}
    \end{matrix}\right),\quad \mathbf{x}\in \R^n
\end{equation}

В случае бинарной классификации, то есть, когда класса два, в роли такой функции выступает сигмоида (уравнение \ref*{eq:sigmoid}, рисунок \ref*{fig:sigmoid}). Тогда выход модели трактуется как вероятность принадлежности объекта первому классу. Если же классов больше двух, то на выходе модели должен получиться вектор, содержащий столько компонент, сколько в задаче классов, и к нему применяется функция $\Softmax$ (уравнение \ref*{eq:softmax}), выход которой удовлетворяет аксиомам вероятности \ref*{eq:prob_axioms}.
\begin{equation}
    \label{eq:prob_axioms}
    \begin{cases}
        \mathbf{y}=\left(\begin{matrix}
            y_1 & y_2 & y_3 & \dots & y_n
        \end{matrix}\right)^\mathsf{T} \\
        y_i \in [0, 1]\,\forall i\in[1, n], \\
        \sum\limits_{i=1}^n y_i = 1
    \end{cases}
\end{equation}

В задаче классификации используется функция потерь, называемая перекрёстной энтропией (уравнение \ref*{eq:ce_loss}). В случае бинарной классификации она представляется в виде \ref*{eq:bce_loss}.
\begin{equation}
    \label{eq:ce_loss}
    \CE(\mathbf{y},\hat{\mathbf{y}})=-\sum\limits_{i=1}^n y_i \ln \hat{y}_i
\end{equation}
\begin{equation}
    \label{eq:bce_loss}
    \BCE(y,\hat{y})=-y \ln \hat{y} - (1-y)\ln (1-\hat{y})
\end{equation}

\subsection{Нелинейная аппроксимация}

Модели линейной и логистической регрессии позволяют строить аппроксимации только гиперплоскостями. Чтобы иметь возможность аппроксимировать нелинейные зависимости в данных, их применяют последовательно, перемежая нелинейными функциями, например, как в уравнении \ref*{eq:nn_sample}. Тогда функция $f(x)$ называется нейронной сетью, а линейные модели, из которых она состоит --- её слоями. Параметры, или веса, нейронной сети, состоят из параметров всех её слоёв, а оптимизируются они так же, градиентными методами.
\begin{equation}
    \label{eq:nn_sample}
    f(x)=\sigma(\dots \sigma(\sigma(xw_1)w_2)w_3 \dots)
\end{equation}

Функции, перемежающие применения линейных слоёв, могут быть любыми кусочно-гладкими нелинейными функциями, а на то, какие операции производятся над слоями внутри нейронной сети, накладывается только одно ограничение: функция $f(x)$ должна оставаться кусочно-гладкой, чтобы можно было искать минимум функции потерь градиентными методами.

\section{Градиентные методы оптимизации}

Минимум функции потерь при обучении нейронных сетей обычно ищется градиентными методами, которые хорошо себя зарекомендовали в решении задач на оптимизацию дифференцируемых функций.

Суть этой группы методов хорошо иллюстрировать на примере простейшего из них --- градиентного спуска.

Пусть имеется задача, представленная в уравнении \ref*{eq:grad_desc_problem}.
\begin{equation}
    \label{eq:grad_desc_problem}
    \begin{cases}
        L(\mathbf{w}): \R^n \rightarrow \R, \\
        \nabla L(\mathbf{w}) = \left(\begin{matrix}
            \frac{\partial L}{\partial w_1}(w_1) &
            \frac{\partial L}{\partial w_2}(w_2) &
            \frac{\partial L}{\partial w_3}(w_3) &
            \hdots &
            \frac{\partial L}{\partial w_n}(w_n)
        \end{matrix}\right)^\mathsf{T}, \\
        L(\mathbf{w}) \rightarrow \min\limits_\mathbf{w}
    \end{cases}
\end{equation}

Требуется найти минимум дифференцируемой функции $n$ переменных. Как известно из курса математического анализа, градиент функции нескольких переменных, вычисленный в конкретной точке --- это вектор, указывающий направление наискорейшего возрастания функции в этой точке. Значит, чтобы найти минимум, двигаясь из какой-либо начальной точки, нужно перемещаться в направлении, противоположном градиенту. Эту идею реализует градиентный спуск (уравнение \ref*{eq:grad_desc_algo}).
\begin{equation}
    \label{eq:grad_desc_algo}
    \mathbf{w}^{t+1}=\mathbf{w}^t-\alpha\nabla L(\mathbf{w})
\end{equation}

Делая шаги длины $\alpha$ в направлении антиградиента функции, с увеличением $t$ алгоритм приближается к минимуму.

Но у этого алгоритма есть ряд проблем, связанных со скроростью сходимости. Наглядный пример приведён на рисунке \ref*{fig:grad_desc_problem}. В нём целевая функция представляет собой вытянутый параболоид, и градиентный спуск в этом случае делает шаги неоптимальным образом, двигаясь к точке минимума очень медленно.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{../inc/images/gradient_descend_problem.png}
    \caption{Проблема долгой сходимости простого градиентного спуска}
    \label{fig:grad_desc_problem}
\end{figure}

Одним из решений этой проблемы является введение физических характеристик для точки, двигающейся по поверхности целевой функции. Например, в методе Adam (англ. --- Adaptive Moment Estimation) вводятся масса и скорость, моделируя движение шарика вниз по неровной поверхности.

Другая проблема состоит в том, что фиксированный шаг градиентного спуска может мешать оптимизации функции по некоторым координатам. В методе Adam это решается путём введения специальных весов, уменьшающих шаг по координатам, которые часто изменяются. Метод Adam описывается уравнениями \ref*{eq:adam}.
\begin{equation}
    \label{eq:adam}
    \begin{cases}
        \mathbf{m}^t=\beta_1\mathbf{m}^{t-1}+(1-\beta_1)\nabla L(\mathbf{w}) \\
        \mathbf{v}^t=\beta_2\mathbf{v}^{t-1}+(1-\beta_2)(\nabla L(\mathbf{w}))^2 \\
        \hat{\mathbf{m}}^t=\frac{\mathbf{m}^t}{1-\beta_1^t} \\
        \hat{\mathbf{v}}^t=\frac{\mathbf{v}^t}{1-\beta_2^t} \\
        \mathbf{w}^{t+1}=\mathbf{t}-\frac{\alpha}{\sqrt{\hat{\mathbf{v}}^t}+\varepsilon}\hat{\mathbf{m}}^t \\
        \mathbf{m}^0=\mathbf{0},\quad\mathbf{v}^0=\mathbf{0}
    \end{cases}
\end{equation}

Параметры $\beta_1$, $\beta_2$, $\varepsilon$ и $\alpha$ задаются по усмотрению пользователя в зависимости от решаемой задачи.

На сегодняшний день Adam является одним из лучших алгоритмов оптимизации, показывающих наименьшее время сходимости при обучении нейронных сетей на разнообразных данных \cite{art:optimizers}.

\section{Токенизация}

Одним из важнейших понятий области обработки естественного языка является токенизация. Так как нейронные сети работают с векторами, то есть, с числами, для решения с их помощью задачи обработки текста требуется эти тексты представлять в виде векторов.

Суть токенизации сводится к дроблению текста на токены, некие элементарные единицы, с последующей их заменой на числа, соответствующие их номерам в списке уникальных токенов текста. Такой подход позволяет однозначно отображать тексты в вектора, которые можно обрабатывать нейронными сетями, а также, наоборот, декодировать текст из векторов.

Токенизация бывает основана на словах, частях слов и символах. У каждого из её видов есть свои преимущества и недостатки.

Так, если брать за токены слова, то теряется информация о словообразовании и словоформах, даже одно слово в разных падежах будет для модели двумя совершенно разными токенами. Зато, если обрезать у слов окончания, то токены будут совпадать, и на таких данных уже можно обучить простую модель, решающую, например, задачу классификации текстов. Но, конечно, такой способ кодирования не подходит для генерации текста ввиду потери важной информации об окончаниях.

Если за токены брать отдельные символы текста, то в теории вся исходная информация из текста сохранится. Но на практике эта информация будет слишком разрежена, и для её использования понадобится слишком сложная модель и огромное количество данных.

В естественном, например, русском языке элементарными единицами словообразования являются морфемы, которые состоят из больше чем одного символа, и разделение текста на них сохранит всю информацию о возможных вариациях слов, которая при этом будет не слишком разреженной. Таким образом, для моделирования языка лучше всего подходит токенизация, берущая за основу части слов.

Но алгоритм деления слов на морфемы очень сложен и узко специализирован для работы с конкретным языком. А в обучающей выборке могут встретиться тексты на разных языках, и нужно, чтобы модель могла их все обработать. Для решения этой задачи существует алгоритм BPE (англ. --- Byte-Pair Encoding), изначально разработанный для сжатия данных.

Суть его состоит в том, что для всех пар символов из обучающей выборки считается частота, с которой они встречаются вместе. Затем самые частотные пары остаются в виде самостоятельных токенов, токены с нулевой частотой отбрасываются, а остальные остаются как есть. Далее процесс повторяется до тех пор, пока не останется возможности объединять токены в пары или пока не будет превышено максимальное число итераций.

Для больших корпусов алгоритм BPE позволяет создать оптимальный словарь токенов при минимальном их числе \cite{art:bpe}.

\section{Языковые модели}

Задача генерации текста на естественном языке сводится к задаче моделирования языка. Языковая модель --- это условное распределение вероятности встретить в тексте токен $w_{n+1}$ сразу после $n$ токенов $\{w_i\}_{i=1}^n$, где $n$ --- длина контекста модели, то есть, максимально возможное количество токенов, влияющих на появление токена $w_{n+1}$.

Нейросетевые языковые модели принимают на вход вектор длины $n$, содержащий токены контекста, и выдают вектор длины, равной количеству токенов в словаре, к которому применяется функция $\Softmax$, чтобы получить вектор, в коротом каждому токену сопоставлена вероятность, что он идёт после заданных $n$ токенов контекста. Такая модель схематично изображена на рисунке \ref*{fig:lang_model} \cite{art:lang_models}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{../inc/images/language_model.png}
    \caption{Простая нейросетевая языковая модель}
    \label{fig:lang_model}
\end{figure}

Как видно, задача языкового моделирования является частным случаем задачи многоклассовой классификации. Поэтому, при обучении в качестве функции потерь используется перекрёстная энтропия.

Для того, чтобы решить задачу генерации текста с помощью языковой модели, нужно просто генерировать случайные числа из распределения, получаемого на выходе функции $\Softmax$, с проведением обратного преобразования токенов в текст, добавлять новый токен в конец вектора контекста с удалением первого и генерацией нового токена до тех пор, пока не будет сгенерирован текст желаемой длины.

\section{Рекуррентные нейронные сети}

Так как текст представляет собой последовательность токенов, а определение языковой модели подразумевает зависимость вероятности следующих токенов от нескольких предыдущих, естественно попробовать реализовать алгоритм его обработки, который бы учитывал эту рекуррентность.

Примером таких моделей являются рекуррентные нейронные сети (англ. --- Recurrent Neural Networks, RNN). Их особенность состоит в наличии так называемого скрытого состояния --- вектора, накапливающего в себе информацию, полученную от поэлементной обработки входной последовательности, как отражено в уравнении \ref*{eq:rnn_hidden_state}. Здесь $x_t$ --- вход слоя, $w_{hh}$, $w_{xh}$, $w_{hy}$ --- обучаемые параметры слоёв сети, $y_t$ --- выход слоя, $h_t$ --- скрытое состояние на шаге $t$, $\Th(\cdot)$ --- гиперболический тангенс (уравнение \ref*{eq:tanh}, рисунок \ref*{fig:tanh}).

\begin{equation}
    \label{eq:rnn_hidden_state}
    \begin{cases}
        h_t = \Th(w_{hh}h_{t-1}+w_{xh}x_t) \\
        y_t = w_{hy}h_t
    \end{cases}
\end{equation}

\begin{equation}
    \label{eq:tanh}
    \Th(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
\end{equation}

Схематическое изображение RNN представлено на рисунке \ref*{fig:rnn}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{../inc/images/rnn.png}
    \caption{Схема работы рекуррентной нейронной сети}
    \label{fig:rnn}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[domain=-6:6]
        \draw[thin,color=gray] (-6.2,-2.2) grid (6.2,2.2);
      
        \draw[line width=0.35mm,->] (-6.2,0) -- (6.2,0) node[right] {$x$};
        \draw[line width=0.35mm,->] (0,-2.2) -- (0,2.2) node[above] {$y$};

        \draw[line width=0.4mm,color=blue,smooth] plot function{(exp(x)-exp(-x))/((exp(x)+exp(-x)))};

        \draw[] (0.05, 1) node[right] {$1$};
        \draw[] (1, -0.05) node[below] {$1$};
    \end{tikzpicture}
    \caption{График гиперболического тангенса}
    \label{fig:tanh}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[domain=-6:6]
        \draw[thin,color=gray] (-6.2,-2.2) grid (6.2,2.2);
      
        \draw[line width=0.35mm,->] (-6.2,0) -- (6.2,0) node[right] {$x$};
        \draw[line width=0.35mm,->] (0,-2.2) -- (0,2.2) node[above] {$y$};

        \draw[line width=0.4mm,color=blue,smooth] plot function{1-((exp(x)-exp(-x))/((exp(x)+exp(-x))))*((exp(x)-exp(-x))/((exp(x)+exp(-x))))};

        \draw[] (0.05, 1) node[right] {$1$};
        \draw[] (1, -0.05) node[below] {$1$};
    \end{tikzpicture}
    \caption{График производной гиперболического тангенса}
    \label{fig:tanh_der}
\end{figure}

Рекуррентные нейронные сети способны улавливать зависимости в последовательных данных, но у них есть недостатки. Как видно на рисунке \ref*{fig:tanh_der}, производная гиперболического тангенса, используемого в качестве функции активации в RNN, почти на всей области определения близка к нулю. На практике это означает, что чем длиннее последовательность данных, тем больше в формуле производной функции потерь будет множителей, близких к нулю, и тем ближе к нулю будут шаги градиентного спуска, что замедляет обучение, а иногда делает его и вовсе невозможным. С этим связана вторая проблема --- новые данные в последовательности оказывают на результат большее влияние, чем старые за счёт многократного умножения последних на близкие к нулю числа. Иными словами можно сказать, что нейросеть <<забывает>> старые данные.

\section{Модификации RNN}

Для решения этой проблемы существует две основных модификации RNN, общая идея которых сводится к введению дополнительных блоков для предсказания степени важности пришедших на вход данных, обеспечивая более контролируемое забывание.

\subsection{GRU}

Архитектура GRU (англ. --- Gated Recurrent Unit) предлагает решать проблему забывания с помощью ряда так называемых вентилей:
\begin{itemize}
    \item вентиль обновления, определяющий количество информации, которое требуется сохранить с предыдущей итерации (уравнение \ref*{eq:gru_update}),
    \item вентиль забывания, определяющий количество информации, которое требуется забыть (уравнение \ref*{eq:gru_reset}),
\end{itemize}

\begin{equation}
    \label{eq:gru_update}
    z_t = \sigma(w_{zx}x_t+w_{zh}h_{t-1})
\end{equation}

\begin{equation}
    \label{eq:gru_reset}
    r_t = \sigma(w_{rx}x_t+w_{rh}h_{t-1})
\end{equation}

Информация, которую будет хранить текущая ячейка сети, рассчитывается по формуле \ref*{eq:gru_current}, а итоговое значение скрытого состояния --- по формуле \ref*{eq:gru_state}.

\begin{equation}
    \label{eq:gru_current}
    c_t = \Th(w_{cx}x_t+w_{ch}r_th_{t-1})
\end{equation}

\begin{equation}
    \label{eq:gru_state}
    h_t = (1-z_t)h_{t-1}+z_tc_t
\end{equation}

Здесь $\sigma(\cdot)$ --- сигмоида, а $w_{zx}$, $w_{zh}$, $w_{rx}$, $w_{rh}$, $w_{cx}$, $w_{ch}$ --- обучаемые параметры слоя.
Схема ячейки GRU изображена на рисунке \ref*{fig:gru}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{../inc/images/gru.png}
    \caption{Схема ячейки GRU}
    \label{fig:gru}
\end{figure}

\subsection{LSTM}

Нейронная сеть с долгой краткосрочной памятью (англ. --- Long Short-Term Memory, LSTM) предлагает решение для борьбы с забыванием, благодаря которому сети удаётся сохранять в 4 раза больше информации, чем обычной RNN \cite{art:rnn}.

Эта архитектура тоже оперирует понятием вентиля, их в ней три:
\begin{itemize}
    \item входной вентиль, контролирующий поток приходящей информации (уравнение \ref*{eq:lstm_input}),
    \item вентиль забывания, управляющий количеством информации, которое требуется сохранить с предыдущей итерации (уравнение \ref*{eq:lstm_forget}),
    \item выходной вентиль, контролирующий поток выходящей информации (уравнение \ref*{eq:lstm_output}).
\end{itemize}

\begin{equation}
    \label{eq:lstm_input}
    i_t = \sigma(w_{ix}x_t+w_{ih}h_{t-1})
\end{equation}

\begin{equation}
    \label{eq:lstm_forget}
    f_t = \sigma(w_{fx}x_t+w_{fh}h_{t-1})
\end{equation}

\begin{equation}
    \label{eq:lstm_output}
    o_t = \sigma(w_{ox}x_t+w_{oh}h_{t-1})
\end{equation}

Далее вычисляются промежуточные значения $g_t$ и $s_t$ (уравнения \ref*{eq:lstm_input_node} и \ref*{eq:lstm_hidden}), а с их помощью считается результирующее скрытое состояние $h_t$ по формуле \ref*{eq:lstm_state}.

\begin{equation}
    \label{eq:lstm_input_node}
    g_t = \Th(w_{gx}x_t+w_{gh}h_{t-1})
\end{equation}

\begin{equation}
    \label{eq:lstm_hidden}
    s_t = s_{t-1}f_t+g_ti_t
\end{equation}

\begin{equation}
    \label{eq:lstm_state}
    h_t = \Th(s_t)o_t
\end{equation}

$w_{ix}$, $w_{ih}$, $w_{fx}$, $w_{fh}$, $w_{ox}$, $w_{oh}$, $w_{gx}$, $w_{gh}$ --- обучаемые параметры.

Схема ячейки LSTM изображена на рисунке \ref*{fig:lstm}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{../inc/images/lstm.png}
    \caption{Схема ячейки LSTM}
    \label{fig:lstm}
\end{figure}

LSTM позволяют частично решить проблему забывания, но за счёт большого числа обучаемых параметров они долго обучаются и занимают много места в памяти. Кроме того, остаётся нерешённой проблема затухающих градиентов.

\section{Механизм внимания}

В задачах преобразования одной последовательности в другую, например, в задаче машинного перевода или преобразования текста в речь, проблема затухающих градиентов может частично решаться с помощью механизма внимания (англ. --- Attention).

Его суть состоит в добавлении в сеть дополнительных параметров, отвечающих за взаимосвязь между отдельными ячейками RNN.

Рассмотрим нейронную сеть, изображённую на рисунке \ref*{fig:seq2seq}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{../inc/images/seq2seq.png}
    \caption{Модель машинного перевода}
    \label{fig:seq2seq}
\end{figure}

Она состоит из двух рекуррентных сетей. Первая RNN принимает на вход предложение и токен за токеном накапливает информацию о нём, получая в скрытом состоянии последней ячейки вектор, кодирующий входное предложение. Вторая RNN принимает на вход этот вектор, а затем каждая её ячейка на основе своего скрытого состояния предсказывает токены слов на русском языке до тех пор, пока не будет предсказан токен конца предложения.

У этого подхода есть существенный недостаток: скрытое состояние последней ячейки первой RNN хранит больше информации о последнем слове предложения, чем об остальных, причём чем раньше слово стоит в предложении, тем меньше информации о нём будет сохранено в силу причин, описанных выше. Получается, что <<развернуть>> из этого вектора предложение, действительно являющегося правильным переводом, маловероятно. Решение этой проблемы предлагает механизм внимания.

Рассмотрим рисунок \ref*{fig:attention}. В отлиличие от рисунка \ref*{fig:seq2seq}, здесь выход ячейки второй RNN зависит не только от скрытого состояния первой сети, но и от скрытого состояния всех остальных ячеек первой RNN с разными весами. Это и есть внимание: в процессе обучения такая архитектура позволяет выводить зависимости выходных данных от разных частей входных, как бы обращая внимание на разные слова входного предложения.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{../inc/images/attention.png}
    \caption{Внимание}
    \label{fig:attention}
\end{figure}

Благодаря тому, что каждая ячейка второй RNN зависит от каждой ячейки первой, информация о входных данных не зануляется, тем самым отчасти решается проблема затухающих градиентов.

\section{Архитектура Transformer}

Архитектура Transformer предлагает совершенно иной подход к нейрсетевой обработке текстовых данных. Её разработчики в своей статье \cite{art:transformer} показывают, что отказавшись от рекуррентных слоёв, можно получить гораздо лучшие результаты работы модели, а также заметно ускорить её обучение.

Вместо рекуррентных слоёв предлагается использовать механизм Self-Attention, близкий по сути к обычному вниманию, описанному выше, но с одним отличием: оба аргумента функции внимания принадлежат одной и той же последовательности. Получается, веса слоёв Self-Attention кодируют внутренние зависимости между токенами входной последовательности.

Слоёв Self-Attention используется сразу несколько --- это позволяет им выучивать разные зависимости, кодируя разного рода отношения между токенами.

В связи с отказом от рекуррентности Transformer не имеет возможности обрабатывать данные произвольной длины. Модели этой архитектуры принимают на вход заранее заданное число токенов --- последовательность длины контекста. С другой стороны, в них нет проблемы затухания градиентов, а информация обо всех токенах учитывается в равной мере, и благодаря этому все лучшие современные языковые модели построены на основе архитектуры Transformer.

Другой позитивный аспект использования множественных независимых слоёв Self-Attention --- это возможность обучать их параллельно на видеокартах, что было невозможно в случае с RNN, где результат каждой ячейки зависел от результата предыдущей.

Схема модели архитектуры Transformer представленая на рисунке \ref*{fig:transformer}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{../inc/images/transformer.png}
    \caption{Transformer}
    \label{fig:transformer}
\end{figure}

Модель состоит из двух смысловых блоков --- кодировщик и декодировщик. Первый возвращает промежуточное векторное представление входной последовательности, а второй снова получает из него текст.

\section{BERT}

Архитектура Transformer позволяет строить очень большие модели, содержащие сотни миллионов вараметров, и обучать их на видеокартах, распараллеливая вычисления. Такие модели способны усваивать гораздо более глубокие закономерности в данных, чем могли RNN, и это можно использовать для построения векторного представления текста --- эмбеддингов (англ. --- Embedding), которые, в свою очередь, можно подать на вход модели классификации и классифицировать тексты.

Для решения этой задачи хорошо подходит первая часть модели Transformer --- кодировщик, возвращающий вектор чисел, который можно использовать в качестве эмбеддинга \cite{art:bert}.

Модель, за основу которой была взята эта идея, называется BERT (англ. --- Bidirectional Encoder Representations from Transformers). Её схема изображена на рисунке \ref*{fig:bert}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../inc/images/bert.png}
    \caption{BERT}
    \label{fig:bert}
\end{figure}

BERT обучается для решения сразу двух задач:
\begin{enumerate}
    \item определение по двум поданным на вход предложениям, с какой вероятностью одно идёт после другого в тексте,
    \item предсказание слов, стоящих на месте пропусков, отмеченных токеном [MASK].
\end{enumerate}

Такой процесс обучения позволяет BERT усваивать глубинные закономерности в устройстве языка и возвращать эмбеддинги, хорошо подходящие для классификации, то есть такие, что в их пространстве кластеры эмбеддингов эквивалентны группам текстов, имеющих общие признаки: тему, жанр, эмоциональную окраску и т. д.

\section{GPT}


