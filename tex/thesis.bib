@Comment А вот так оформляется библиография при помощи BibTeX.

@online{art:psy_test,
  title = {Диагностика эмпатии по А. Меграбяну и Н. Эпштейну},
  url = {https://hrliga.com/index.php?module=profession&op=view&id=847},
  urldate = {23.05.2022},
  language = {russian}
}

@online{art:models_review,
  author = {Mariya Yao},
  title = {10 Leading Language Models For NLP In 2021},
  url = {https://www.topbots.com/leading-nlp-language-models-2020/},
  urldate = {17.04.2022},
  language = "russian"
}

@online{art:sber_pr,
  title = {RuGPT-3 – AI-модель для написания текстов для разработчиков, обработка естественного языка},
  url = {https://developers.sber.ru/portal/products/rugpt-3ysclid=l249jkw241&attempt=1},
  urldate = {18.04.2022},
  language = {russian}
}

@online{gh:sber,
  title = {ru-gpts},
  url = {https://github.com/ai-forever/ru-gpts},
  urldate = {17.04.2022},
  language = "russian"
}

@online{doc:streamlit,
  title = "Streamlit documentation",
  url = "https://docs.streamlit.io/",
  urldate = "18.04.2022",
  language = "russian"
}

@online{art:linear_models,
  title = "Открытый курс машинного обучения. Тема 4. Линейные модели классификации и регрессии",
  url = "https://habr.com/ru/company/ods/blog/323890/",
  urldate = "26.05.2022",
  language = "russian"
}

@online{art:optimizers,
  author = "Sebastian Ruder",
  title = "An overview of gradient descent optimization algorithms",
  url = "https://arxiv.org/abs/1609.04747",
  urldate = "25.05.2022",
  language = "russian"
}

@online{doc:docker,
  title = "Docker overview",
  url = "https://docs.docker.com/get-started/overview/",
  urldate = "25.05.2022",
  language = "russian"
}  

@online{art:bpe,
  author = "Rico Sennrich, Barry Haddow, Alexandra Birch",
  title = "Neural Machine Translation of Rare Words with Subword Units",
  url = "https://aclanthology.org/P16-1162.pdf",
  urldate = "25.05.2022",
  language = "russian"
}

@online{art:lang_models,
  author = "Mor Kapronczay",
  title = "A beginner’s guide to language models",
  url = "https://towardsdatascience.com/the-beginners-guide-to-language-models-aa47165b57f9",
  urldate = "25.05.2022",
  language = "russian"
}

@online{art:rnn,
  author = "Ismail Mebsout",
  title = "Recurrent Neural Networks",
  url = "https://towardsdatascience.com/recurrent-neural-networks-b7719b362c65",
  urldate = "27.05.2022",
  language = "russian"
}

@online{art:transformer,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  title = "Attention Is All You Need",
  url = "https://arxiv.org/abs/1706.03762",
  urldate = "29.05.2022",
  language = "russian"
}

@online{art:bert,
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  url = {https://arxiv.org/abs/1810.04805},
  urldate = {29.05.2022},
  language = {russian}
}

@online{art:gpt3,
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  title = {Language Models are Few-Shot Learners},
  url = {https://arxiv.org/abs/2005.14165},
  urldate = {29.05.2022},
  language = {russian}
}
